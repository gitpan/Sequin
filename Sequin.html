<HTML>
<HEAD>
<TITLE>URI::Sequin - Extract information from the URLs of Search-Engines</TITLE>

</HEAD>

<BODY>

<!-- INDEX BEGIN -->

<UL>

	<LI><A HREF="#NAME">NAME</A>
	<LI><A HREF="#SYNOPSIS">SYNOPSIS</A>
	<LI><A HREF="#DESCRIPTION">DESCRIPTION</A>
	<LI><A HREF="#AUTHOR">AUTHOR</A>
	<LI><A HREF="#COPYRIGHT">COPYRIGHT</A>
</UL>
<!-- INDEX END -->

<HR>
<P>
<H1><A NAME="NAME">NAME</A></H1>
<P>
<PRE>        URI::Sequin - Extract information from the URLs of Search-Engines
</PRE>
<P>
<HR>
<H1><A NAME="SYNOPSIS">SYNOPSIS</A></H1>
<P>
<PRE>        use URI::Sequin qw/se_extract key_extract log_extract %log_types/;
</PRE>
<P>
<PRE>        $url = &amp;log_extract($line_from_log_file, 'NCSA');
</PRE>
<P>
<PRE>        $log_types{'MyLogType'} = '^(.+?) -&gt; .+$';
        $url = &amp;log_extract($line_from_log_file, 'MyLogType');
</PRE>
<P>
<PRE>        $keyword_string = &amp;key_extract($url);
</PRE>
<P>
<PRE>        ($search_engine_name, $search_engine_url) = @{&amp;se_extract($url)};
</PRE>
<P>
<HR>
<H1><A NAME="DESCRIPTION">DESCRIPTION</A></H1>
<P>
This module provides three tools to aid people trying to analyse
Search-Engine URLs. It’s meant mainly for those who want to analyse
referrer logs and pick out key information about site visitors, such as
which Search-Engine and keywords they used to find the site.

<P>
The functions and globals provided (and exported by default) from this
module are:

<DL>
<DT><STRONG><A NAME="item_log_extract">log_extract($log_line, ‘Type’)</A></STRONG><DD>
<P>
This will pick out the referring URL from a line of a logfile. The ‘type’
can be one of the built in types or can be a user-created one. For more
information, see <CODE>%log_types</CODE> below. This subroutine accepts a
scalar, and returns a scalar.

<DT><STRONG><A NAME="item_key_extract">key_extract($url)</A></STRONG><DD>
<P>
This will try and determine the keywords used in $url. It accepts a scalar
and returns a scalar. Should nothing be found, it returns an undefined
value.

<DT><STRONG><A NAME="item_se_extract">se_extract($url)</A></STRONG><DD>
<P>
This will try and determine the name of the Search-Engine used and its URL.
It accepts a scalar, and returns an array containing firstly the Search-
Engine’s name and secondly the Search-Engine’s URL. Should the URL appear
not to be from a Search Query, it returns a reference to an empty array.

<DT><STRONG><A NAME="item__log_types">%log_types</A></STRONG><DD>
<P>
There are five built-in logfile types already in this hash. They are:

<UL>
<LI><STRONG><A NAME="item_IIS1">IIS1 - Microsoft IIS 3.0 and 2.0</A></STRONG>
<LI><STRONG><A NAME="item_IIS2">IIS2 - Microsoft IIS4.0 (W3SVC format)</A></STRONG>
<LI><STRONG><A NAME="item_NCSA">NCSA - For APACHE, NETSCAPE and any other NCSA format logs</A></STRONG>
<LI><STRONG><A NAME="item_ORW">ORW - O'Reilly WebSite format</A></STRONG>
<LI><STRONG><A NAME="item_General">General - A generalised one that will work with most logfiles</A></STRONG>
</UL>
<P>
It’s easy to add another one. Simply add a key to the hash, with a value
that is a regex. Parenthesise the part that is the referring URL, as the
script uses <CODE>$1</CODE> to obtain the URL. (see the example in the
Synopsis section).

</DL>
<P>
<HR>
<H1><A NAME="AUTHOR">AUTHOR</A></H1>
<P>
Peter Sergeant &lt;<A HREF="mailto:pete_sergeant@hotmail.com">pete_sergeant@hotmail.com</A>&gt;



<P>
<HR>
<H1><A NAME="COPYRIGHT">COPYRIGHT</A></H1>
<P>
Copyright 2000 Peter Sergeant.

<P>
This program is free software; you can redistribute it and/or modify it
under the same terms as Perl itself.

</BODY>

</HTML>
